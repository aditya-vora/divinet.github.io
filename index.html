<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="DiViNeT: 3D Reconstruction from Disparate Views using Neural Template Regularization.">
  <meta name="keywords" content="Surface Reconstruction, NeRF">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>DiViNeT: 3D Reconstruction from Disparate Views using Neural Template Regularization</title>

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <!-- <link rel="icon" href="./static/images/favicon.svg"> -->

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">DiViNeT: 3D Reconstruction from Disparate Views using Neural Template Regularization</h1>
          <h2 class="title is-size-3 publication-title">NeurIPS 2023</h2>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://aditya-vora.github.io/">Aditya Vora</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://agp-ka32.github.io/">Akshay Gadi Patil</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://www2.cs.sfu.ca/~haoz/index.html">Hao (Richard) Zhang</a><sup>1,2</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Simon Fraser University,</span>
            <span class="author-block"><sup>2</sup>Amazon</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2306.04699.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2306.04699"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <!-- <span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/aditya-vora/divinet"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <!-- <span class="link-block">
                <a href="https://github.com/google/nerfies/releases/tag/0.1"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a> -->
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Overview</h2>
        <p>
          Given a set of sparse view images of a scene from different views and their corresponding camera poses,
          DiviNet predicts surface priors in the form of templates (3D gaussian functions) which is then used to regularize
          the surface reconstruction process in the volume rendering framework. This template prediction network is trained 
          across a dataset of objects with sparse point cloud reconstructed from multi views as supervision. Our method can reconstruct 
          the surface under sparse conditions without using any explicit fine-grained ground-truth like depth maps.
        </p>
    
      </div>
    </div>
    <div class="hero-body">
      <embed src="static/images/camera_ready_pipeline_fig.png" alt="Concept of our method" width="900" height="300">
      <h2 class="subtitle has-text-centered">
        <span class="dnerf">DiviNet</span> operates in two stages. In the first stage it learns a template prediction network and in the second stage uses the predicted templates to regularize the reconstruction.
      </h2>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3">Surface Reconstruction on DTU Dataset</h2>
        <p>
          Our method faithfully reconstructs the geometry from under sparse conditions. We use the same set of images which are used by <a href="https://m-niemeyer.github.io/regnerf/">RegNerf</a>.
        </p>
        <br>
        <div class="columns is-vcentered interpolation-panel">
          <div class="column is-3 has-text-centered">
            <img src="./static/images/40.png"
                 class="input-image"
                 alt="reference image."/>
          </div>
          <div class="column is-3 has-text-centered">
            <video poster="" id="36" autoplay controls muted loop playsinline width="200" height="100">
              <source src="./static/videos/new40.mp4"
                      type="video/mp4">
            </video>
          </div>
          <div class="column is-3 has-text-centered">
            <img src="./static/images/55.png"
                 class="input-image"
                 alt="reference image."/>
          </div>
          <div class="item item-8">
            <video poster="" id="8" autoplay controls muted loop playsinline width="200" height="100">
              <source src="./static/videos/new55.mp4"
                      type="video/mp4">
            </video>
          </div>
        </div>

        <div class="columns is-vcentered interpolation-panel">
          <div class="column is-3 has-text-centered">
            <img src="./static/images/24.png"
                 class="input-image"
                 alt="reference image."/>
          </div>

          <div class="column is-3 has-text-centered">
            <video poster="" id="36" autoplay controls muted loop playsinline width="200" height="100">
              <source src="./static/videos/new24.mp4"
                      type="video/mp4">
            </video>
          </div>

          <div class="column is-3 has-text-centered">
            <img src="./static/images/65.png"
                 class="input-image"
                 alt="reference image."/>
          </div>

          <div class="item item-20">
            <video poster="" id="20" autoplay controls muted loop playsinline width="200" height="100">
              <source src="./static/videos/new65.mp4"
                      type="video/mp4">
            </video>
          </div>

        </div>

        <div class="columns is-vcentered interpolation-panel">
          <div class="column is-3 has-text-centered">
            <img src="./static/images/69.png"
                  class="input-image"
                  alt="reference image."/>
          </div>
          <div class="column is-3 has-text-centered">
            <video poster="" id="36" autoplay controls muted loop playsinline width="200" height="100">
              <source src="./static/videos/new69.mp4"
                      type="video/mp4">
            </video>
          </div>
          <div class="column is-3 has-text-centered">
            <img src="./static/images/83.png"
                  class="input-image"
                  alt="reference image."/>
          </div>
          <div class="item item-20">
            <video poster="" id="20" autoplay controls muted loop playsinline width="200" height="100">
              <source src="./static/videos/new83.mp4"
                      type="video/mp4">
            </video>
          </div>
        </div>


        <div class="columns is-vcentered interpolation-panel">
          <div class="column is-3 has-text-centered">
            <img src="./static/images/97.png"
                  class="input-image"
                  alt="reference image."/>
          </div>
          <div class="column is-3 has-text-centered">
            <video poster="" id="36" autoplay controls muted loop playsinline width="200" height="100">
              <source src="./static/videos/new97.mp4"
                      type="video/mp4">
            </video>
          </div>
          <div class="column is-3 has-text-centered">
            <img src="./static/images/105.png"
                  class="input-image"
                  alt="reference image."/>
          </div>
          <div class="item item-20">
            <video poster="" id="20" autoplay controls muted loop playsinline width="200" height="100">
              <source src="./static/videos/new105.mp4"
                      type="video/mp4">
            </video>
          </div>
        </div>


        <div class="columns is-vcentered interpolation-panel">
          <div class="column is-3 has-text-centered">
            <img src="./static/images/106.png"
                  class="input-image"
                  alt="reference image."/>
          </div>
          <div class="column is-3 has-text-centered">
            <video poster="" id="36" autoplay controls muted loop playsinline width="200" height="100">
              <source src="./static/videos/new106.mp4"
                      type="video/mp4">
            </video>
          </div>
          <div class="column is-3 has-text-centered">
            <img src="./static/images/114.png"
                  class="input-image"
                  alt="reference image."/>
          </div>
          <div class="item item-20">
            <video poster="" id="20" autoplay controls muted loop playsinline width="200" height="100">
              <source src="./static/videos/new114.mp4"
                      type="video/mp4">
            </video>
          </div>
        </div>

        <div class="columns is-vcentered interpolation-panel">
          <div class="column is-3 has-text-centered">
            <img src="./static/images/118.png"
                  class="input-image"
                  alt="reference image."/>
          </div>
          <div class="column is-3 has-text-centered">
            <video poster="" id="36" autoplay controls muted loop playsinline width="200" height="100">
              <source src="./static/videos/new118.mp4"
                      type="video/mp4">
            </video>
          </div>
          <div class="column is-3 has-text-centered">
            <img src="./static/images/122.png"
                  class="input-image"
                  alt="reference image."/>
          </div>
          <div class="item item-20">
            <video poster="" id="20" autoplay controls muted loop playsinline width="200" height="100">
              <source src="./static/videos/new122.mp4"
                      type="video/mp4">
            </video>
          </div>
        </div>

        <h2 class="subtitle has-text-centered">
          Results of <b>sparse view</b> (3 disparate views) reconstruction on DTU Dataset.
    
      </div>
    </div>
    <!--/ Concurrent Work. -->

  </div> 
</section>



<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3">Surface Reconstruction on BlendedMVS Dataset</h2>
        <p>
          We show the surface reconstruction results of objects from BlendedMVS dataset under sparse view scenario. As it can be seen DiviNet can 
          faithfully reconstruct highly detailed surface even on complex real-world dataset.
        </p>
        <br>
        <div class="columns is-vcentered interpolation-panel">
          <div class="column is-3 has-text-centered">
            <img src="./static/images/bmvs_scan36/joint.png"
                 class="input-image"
                 alt="reference image."/>
          </div>
          <div class="column is-3 has-text-centered">
            <video poster="" id="36" autoplay controls muted loop playsinline width="200" height="100">
              <source src="./static/videos/new36.mp4"
                      type="video/mp4">
            </video>
          </div>
          <div class="column is-3 has-text-centered">
            <img src="./static/images/bmvs_scan8/joint.png"
                 class="input-image"
                 alt="reference image."/>
          </div>
          <div class="item item-8">
            <video poster="" id="8" autoplay controls muted loop playsinline width="200" height="100">
              <source src="./static/videos/new8.mp4"
                      type="video/mp4">
            </video>
          </div>
        </div>

        <div class="columns is-vcentered interpolation-panel">
          <div class="column is-3 has-text-centered">
            <img src="./static/images/bmvs_scan23/joint_scan23.png"
                 class="input-image"
                 alt="reference image."/>
          </div>
          <div class="column is-3 has-text-centered">
            <video poster="" id="36" autoplay controls muted loop playsinline width="200" height="100">
              <source src="./static/videos/new23.mp4"
                      type="video/mp4">
            </video>
          </div>
          <div class="column is-3 has-text-centered">
            <img src="./static/images/bmvs_scan20/joint.png"
                 class="input-image"
                 alt="reference image."/>
          </div>
          <div class="item item-20">
            <video poster="" id="20" autoplay controls muted loop playsinline width="200" height="100">
              <source src="./static/videos/new20.mp4"
                      type="video/mp4">
            </video>
          </div>
        </div>

        <h2 class="subtitle has-text-centered">
          Results of <b>sparse view</b> (3 disparate views) reconstruction on BlendedMVS Dataset.
    
      </div>
    </div>
    <!--/ Concurrent Work. -->

  </div> 
</section>

<!-- <section class="section">
  <div class="container is-max-desktop">
    Abstract.
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            We present a volume rendering-based neural surface reconstruction method that
            takes as few as three disparate RGB images as input. Our key idea is to regularize
            the reconstruction, which is severely ill-posed and leaving significant gaps between
            the sparse views, by learning a set of neural templates that act as surface priors.
            Our method, coined DiViNet, operates in two stages. The first stage learns the
            templates, in the form of 3D Gaussian functions, across different scenes, without
            3D supervision. In the reconstruction stage, our predicted templates serve as
            anchors to help “stitch” the surfaces over sparse regions. We demonstrate that our
            approach is not only able to complete the surface geometry but also reconstructs
            surface details to a reasonable extent from few disparate input views. On the DTU
            and BlendedMVS datasets, our approach achieves the best reconstruction quality
            among existing methods in the presence of such sparse views, and performs on par,
            if not better, with competing methods when dense views are employed as inputs.
          </p>
        </div>
      </div>
    </div>
    / Abstract. -->

    <!-- Paper video. -->
    <!-- <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/MrKrnHhk8IA?rel=0&amp;showinfo=0"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div> -->
    <!--/ Paper video. -->
  </div>
</section> 



<!-- <section class="hero is-light is-small">
  <div class="hero-body">
    <h2 class="title is-3">Surface Reconstruction Results from DTU dataset</h2>
    <p> Our method faithfully reconstructs the geometry from DTU dataset when 3 images are used as input. We use the same set of images which are used by <a href="https://m-niemeyer.github.io/regnerf/">RegNerf</a>.</p>
    <br>
  
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-65">
          <video poster="" id="65" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/new65.mp4"
                    type="video/mp4">
          </video>
        </div>

        <div class="item item-40">
          <video poster="" id="40" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/new40.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-55">
          <video poster="" id="55" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/new55.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-24">
          <video poster="" id="24" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/new24.mp4"
                    type="video/mp4">
          </video>
        </div>

        <div class="item item-69">
          <video poster="" id="69" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/new69.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-83">
          <video poster="" id="83" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/new83.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-97">
          <video poster="" id="97" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/new97.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-105">
          <video poster="" id="105" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/new105.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-106">
          <video poster="" id="106" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/new106.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-114">
          <video poster="" id="114" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/new114.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-118">
          <video poster="" id="118" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/new118.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-122">
          <video poster="" id="122" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/new122.mp4"
                    type="video/mp4">
          </video>
        </div>  
      </div>
    </div>
    <h2 class="subtitle has-text-centered">
      Results of <b>sparse view</b> (3 disparate views) reconstruction on DTU Dataset.

  </div>
</section>  -->



<section class="details">
  <div class="container is-max-desktop">
    <h2 class="title is-3">Surface Details</h2>
    Since we do not use explict priors like depth maps which are often smooth and have low resolution, our method is able to reconstruct surface with much better details then previous methods which use explicit priors like depth maps.    
    <div class="hero-body">
      <center><embed src="static/images/details.png" alt="Concept of our method" width="850" height="300"></center>
      <h2 class="subtitle has-text-centered">
        DiviNet can reconstruct better surface details compared to previous methods.
      </h2>
    </div>
  </div>
</section>




<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{vora2023divinet,
      title={DiViNeT: 3D Reconstruction from Disparate Views via Neural Template Regularization},
      author={Vora, Aditya and Patil, Akshay Gadi and Zhang, Hao},
      journal={arXiv preprint arXiv:2306.04699},
      year={2023}
    }
    </code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

<script type="text/javascript">

  $(document).ready(function () {
    // Add smooth scrolling to all links
    $("a").on('click', function (event) {

      // Make sure this.hash has a value before overriding default behavior
      if (this.hash !== "") {
        // Prevent default anchor click behavior
        event.preventDefault();

        // Store hash
        var hash = this.hash;

        // Using jQuery's animate() method to add smooth page scroll
        // The optional number (800) specifies the number of milliseconds it takes to scroll to the specified area
        $('html, body').animate({
          scrollTop: $(hash).offset().top
        }, 600, function () {

          // Add hash (#) to URL when done scrolling (default click behavior)
          window.location.hash = hash;
        });
      } // End if
    });
  });

</script>
</body>
</html>
